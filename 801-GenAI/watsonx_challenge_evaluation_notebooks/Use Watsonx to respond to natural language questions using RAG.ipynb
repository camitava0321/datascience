{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n",
    "# Use Watsonx to respond to natural language questions using RAG approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Please note that for the watsonx challenge, please run these notebooks locally on your laptop/desktop and do not run it in IBM Cloud.  The instructions for running the notebook locally are provided in the readme.md file present in the zip file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This notebook contains the steps and code to demonstrate support of Retrieval Augumented Generation in watsonx.ai. It introduces commands for data retrieval, knowledge base building & querying, and model testing.\n",
    "\n",
    "Some familiarity with Python is helpful. This notebook uses Python 3.10.\n",
    "\n",
    "#### About Retrieval Augmented Generation\n",
    "Retrieval Augmented Generation (RAG) is a versatile pattern that can unlock a number of use cases requiring factual recall of information, such as querying a knowledge base in natural language.\n",
    "\n",
    "In its simplest form, RAG requires 3 steps:\n",
    "\n",
    "- Index knowledge base passages (once)\n",
    "- Retrieve relevant passage(s) from knowledge base (for every user query)\n",
    "- Generate a response by feeding retrieved passage into a large language model (for every user query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"setup\"></a>\n",
    "##  Set up the environment\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Install and import dependecies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: exceptiongroup in ./.conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette==0.20.4->fastapi==0.85.1->chromadb==0.3.27) (1.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./.conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: tqdm in ./.conda/lib/python3.10/site-packages (from nltk->rouge_score) (4.65.0)\n",
      "Requirement already satisfied: tqdm in ./.conda/lib/python3.10/site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: six>=1.10.0 in ./.conda/lib/python3.10/site-packages (from lomond->ibm-watson-machine-learning>=1.0.312) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install chromadb==0.3.27 | tail -n 1\n",
    "!pip install sentence_transformers | tail -n 1\n",
    "!pip install pandas | tail -n 1\n",
    "!pip install rouge_score | tail -n 1\n",
    "!pip install nltk | tail -n 1\n",
    "!pip install \"ibm-watson-machine-learning>=1.0.312\" | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Please restart the notebook kernel to pick up proper version of packages installed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "import pandas as pd\n",
    "from typing import Optional, Dict, Any, Iterable, List\n",
    "\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "except ImportError:\n",
    "    raise ImportError(\"Could not import sentence_transformers: Please install sentence-transformers package.\")\n",
    "    \n",
    "try:\n",
    "    import chromadb\n",
    "    from chromadb.api.types import EmbeddingFunction\n",
    "except ImportError:\n",
    "    raise ImportError(\"Could not import chromdb: Please install chromadb package.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Watsonx API connection\n",
    "This cell defines the credentials required to work with watsonx API for Foundation\n",
    "Model inferencing.\n",
    "\n",
    "**Action:** Provide the IBM Cloud user API key. For details, see\n",
    "[documentation](https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "credentials = {\n",
    "    \"url\": \"https://us-south.ml.cloud.ibm.com\",\n",
    "    \"apikey\": getpass.getpass(\"Please enter your WML api key (hit enter): \")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Defining the project id\n",
    "The API requires project id that provides the context for the call. We will obtain the id from the project in which this notebook runs. Otherwise, please provide the project id.\n",
    "\n",
    "**Hint**: You can find the `project_id` as follows. Open the prompt lab in watsonx.ai. At the very top of the UI, there will be `Projects / <project name> /`. Click on the `<project name>` link. Then get the `project_id` from Project's Manage tab (Project -> Manage -> General -> Details).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    project_id = os.environ[\"PROJECT_ID\"]\n",
    "except KeyError:\n",
    "    project_id = input(\"Please enter your project_id (hit enter): \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"data\"></a>\n",
    "## Train/test data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Load train and test datasets. At first, training dataset (`train_data`) should be used to work with the models to prepare and tune prompt. Then, test dataset (`test_data`) should be used to calculate the metrics score for selected model, defined prompts and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_test = 'data/RAG/nq910_400_instances/test.tsv'\n",
    "filename_train = 'data/RAG/nq910_400_instances/train.tsv'\n",
    "\n",
    "test_data = pd.read_csv(filename_test, delimiter='\\t')\n",
    "train_data = pd.read_csv(filename_train, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question</th>\n",
       "      <th>relevant</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8519</td>\n",
       "      <td>when was the cathedral of santa maria del fior...</td>\n",
       "      <td>136</td>\n",
       "      <td>begun in 1296::completed by 1436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>852</td>\n",
       "      <td>who plays cassidy on law and order svu</td>\n",
       "      <td>177</td>\n",
       "      <td>Dean Winters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7600</td>\n",
       "      <td>who was the old woman in phantom of the opera</td>\n",
       "      <td>642</td>\n",
       "      <td>Madame Giry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4258</td>\n",
       "      <td>when is the finals of americas got talent 2017</td>\n",
       "      <td>781</td>\n",
       "      <td>September 20 , 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8272</td>\n",
       "      <td>who played the frog in gnomeo and juliet</td>\n",
       "      <td>1018</td>\n",
       "      <td>Ashley Jensen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    qid                                           question relevant  \\\n",
       "0  8519  when was the cathedral of santa maria del fior...      136   \n",
       "1   852             who plays cassidy on law and order svu      177   \n",
       "2  7600      who was the old woman in phantom of the opera      642   \n",
       "3  4258     when is the finals of americas got talent 2017      781   \n",
       "4  8272           who played the frog in gnomeo and juliet     1018   \n",
       "\n",
       "                            answers  \n",
       "0  begun in 1296::completed by 1436  \n",
       "1                      Dean Winters  \n",
       "2                       Madame Giry  \n",
       "3               September 20 , 2017  \n",
       "4                     Ashley Jensen  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question</th>\n",
       "      <th>relevant</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5555</td>\n",
       "      <td>who did chris carter play for last year</td>\n",
       "      <td>267</td>\n",
       "      <td>Milwaukee Brewers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6654</td>\n",
       "      <td>what is the latest version of safari on mac</td>\n",
       "      <td>664</td>\n",
       "      <td>Safari 11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3396</td>\n",
       "      <td>when did bucharest become the capital of romania</td>\n",
       "      <td>944</td>\n",
       "      <td>1862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8198</td>\n",
       "      <td>who did jeffrey dean morgan play on supernatural</td>\n",
       "      <td>1398</td>\n",
       "      <td>John Eric Winchester</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4526</td>\n",
       "      <td>who is the shortest man that ever lived</td>\n",
       "      <td>1522</td>\n",
       "      <td>Chandra Bahadur Dangi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    qid                                          question  relevant  \\\n",
       "0  5555           who did chris carter play for last year       267   \n",
       "1  6654       what is the latest version of safari on mac       664   \n",
       "2  3396  when did bucharest become the capital of romania       944   \n",
       "3  8198  who did jeffrey dean morgan play on supernatural      1398   \n",
       "4  4526           who is the shortest man that ever lived      1522   \n",
       "\n",
       "                 answers  \n",
       "0      Milwaukee Brewers  \n",
       "1              Safari 11  \n",
       "2                   1862  \n",
       "3   John Eric Winchester  \n",
       "4  Chandra Bahadur Dangi  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Build up knowledge base\n",
    "\n",
    "The current state-of-the-art in RAG is to create dense vector representations of the knowledge base in order to calculate the semantic similarity to a given user query.\n",
    "\n",
    "We can generate dense vector representations using embedding models. In this notebook, we use [SentenceTransformers](https://www.google.com/search?client=safari&rls=en&q=sentencetransformers&ie=UTF-8&oe=UTF-8) [all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) to embed both the knowledge base passages and user queries. `all-MiniLM-L6-v2` is a performant open-source model that is small enough to run locally.\n",
    "\n",
    "A vector database is optimized for dense vector indexing and retrieval. This notebook uses [Chroma](https://docs.trychroma.com), a user-friendly open-source vector database, licensed under Apache 2.0, which offers good speed and performance with all-MiniLM-L6-v2 embedding model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The dataset we are using is already split into self-contained passages that can be ingested by Chroma. \n",
    "\n",
    "The size of each passage is limited by the embedding model's context window (which is 256 tokens for `all-MiniLM-L6-v2`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load knowledge base documents\n",
    "\n",
    "Load set of documents used further to build knowledge base. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"data\"\n",
    "knowledge_base_dir = f\"{data_root}/knowledge_base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(knowledge_base_dir):\n",
    "    from zipfile import ZipFile\n",
    "    with ZipFile(knowledge_base_dir + \".zip\", 'r') as zObject:\n",
    "        zObject.extractall(data_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = pd.read_csv(f\"{knowledge_base_dir}/psgs.tsv\", sep='\\t', header=0)\n",
    "documents['indextext'] = documents['title'].astype(str) + \"\\n\" + documents['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Create an embedding function\n",
    "\n",
    "Note that you can feed a custom embedding function to be used by chromadb. The performance of chromadb may differ depending on the embedding model used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MiniLML6V2EmbeddingFunction(EmbeddingFunction):\n",
    "    MODEL = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    def __call__(self, texts):\n",
    "        return MiniLML6V2EmbeddingFunction.MODEL.encode(texts).tolist()\n",
    "emb_func = MiniLML6V2EmbeddingFunction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Set up Chroma upsert\n",
    "\n",
    "Upserting a document means update the document even if it exists in the database. Otherwise re-inserting a document throws an error. This is useful for experimentation purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pip install sentence_transformers\n",
    "class ChromaWithUpsert:\n",
    "    def __init__(\n",
    "            self,\n",
    "            name: Optional[str] = \"watsonx_rag_collection\",\n",
    "            persist_directory:Optional[str]=None,\n",
    "            embedding_function: Optional[EmbeddingFunction]=None,\n",
    "            collection_metadata: Optional[Dict] = None,\n",
    "    ):\n",
    "        self._client_settings = chromadb.config.Settings()\n",
    "        if persist_directory is not None:\n",
    "            self._client_settings = chromadb.config.Settings(\n",
    "                chroma_db_impl=\"duckdb+parquet\",\n",
    "                persist_directory=persist_directory,\n",
    "            )\n",
    "        self._client = chromadb.Client(self._client_settings)\n",
    "        self._embedding_function = embedding_function\n",
    "        self._persist_directory = persist_directory\n",
    "        self._name = name\n",
    "        self._collection = self._client.get_or_create_collection(\n",
    "            name=self._name,\n",
    "            embedding_function=self._embedding_function\n",
    "            if self._embedding_function is not None\n",
    "            else None,\n",
    "            metadata=collection_metadata,\n",
    "        )\n",
    "\n",
    "    def upsert_texts(\n",
    "        self,\n",
    "        texts: Iterable[str],\n",
    "        metadata: Optional[List[dict]] = None,\n",
    "        ids: Optional[List[str]] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> List[str]:\n",
    "        \"\"\"Run more texts through the embeddings and add to the vectorstore.\n",
    "        Args:\n",
    "            :param texts (Iterable[str]): Texts to add to the vectorstore.\n",
    "            :param metadatas (Optional[List[dict]], optional): Optional list of metadatas.\n",
    "            :param ids (Optional[List[str]], optional): Optional list of IDs.\n",
    "            :param metadata: Optional[List[dict]] - optional metadata (such as title, etc.)\n",
    "        Returns:\n",
    "            List[str]: List of IDs of the added texts.\n",
    "        \"\"\"\n",
    "        # TODO: Handle the case where the user doesn't provide ids on the Collection\n",
    "        if ids is None:\n",
    "            import uuid\n",
    "            ids = [str(uuid.uuid1()) for _ in texts]\n",
    "        embeddings = None\n",
    "        self._collection.upsert(\n",
    "            metadatas=metadata, documents=texts, ids=ids\n",
    "        )\n",
    "        return ids\n",
    "\n",
    "    def is_empty(self):\n",
    "        return self._collection.count()==0\n",
    "\n",
    "    def persist(self):\n",
    "        self._client.persist()\n",
    "\n",
    "    def query(self, query_texts:str, n_results:int=5):\n",
    "        \"\"\"\n",
    "        Returns the closests vector to the question vector\n",
    "        :param query_texts: the question\n",
    "        :param n_results: number of results to generate\n",
    "        :return: the closest result to the given question\n",
    "        \"\"\"\n",
    "        return self._collection.query(query_texts=query_texts, n_results=n_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Embed and index documents with Chroma\n",
    "\n",
    "**Note: Could take several minutes if you don't have pre-built indices**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 745 ms, sys: 101 ms, total: 845 ms\n",
      "Wall time: 551 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "chroma = ChromaWithUpsert(\n",
    "    name=f\"nq910_minilm6v2\",\n",
    "    embedding_function=emb_func,  # you can have something here using /embed endpoint\n",
    "    persist_directory=knowledge_base_dir,\n",
    ")\n",
    "if chroma.is_empty():\n",
    "    _ = chroma.upsert_texts(\n",
    "        texts=documents.indextext.tolist(),\n",
    "        # we handle tokenization, embedding, and indexing automatically. You can skip that and add your own embeddings as well\n",
    "        metadata=[{'title': title, 'id': id}\n",
    "                  for (title,id) in\n",
    "                  zip(documents.title, documents.id)],  # filter on these!\n",
    "        ids=[str(i) for i in documents.id],  # unique for each doc\n",
    "    )\n",
    "    chroma.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"models\"></a>\n",
    "## Foundation Models on Watsonx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You need to specify `model_id` that will be used for inferencing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Action**: Use `FLAN_UL2` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning.foundation_models.utils.enums import ModelTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_id = ModelTypes.FLAN_UL2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"predict\"></a>\n",
    "## Generate a retrieval-augmented response to a question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Select questions\n",
    "\n",
    "Get questions from the previously loaded test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "who did chris carter play for last year?\n",
      "what is the latest version of safari on mac?\n",
      "when did bucharest become the capital of romania?\n",
      "who did jeffrey dean morgan play on supernatural?\n",
      "who is the shortest man that ever lived?\n",
      "how many seconds do you have to throw a grenade?\n",
      "who is known as a father of indian cricket?\n",
      "what is the name of the period in japanese history that began in 1868?\n",
      "harold and kumar go to white castle where was it filmed?\n",
      "how many games have the capitals won in the playoffs?\n",
      "what is the best selling nintendo game of all time?\n",
      "korean movie about a man on an island?\n",
      "who plays lorelai in hannah montana the movie?\n",
      "what season of greys anatomy was the plane crash?\n",
      "who made call of duty black ops 2?\n",
      "when was the last solar eclipse seen in north america?\n",
      "who is hosting the fifa world cup in 2022?\n",
      "what is the record for wins in major league baseball?\n",
      "big boss 2 telugu set location in hyderabad?\n",
      "who did the us support in the korean war?\n",
      "what is the caterpillar smoking in alice in wonderland?\n",
      "how much aid does us give to other countries?\n",
      "who plays jake on two and a half?\n",
      "what do you call a bundle of hay?\n",
      "how many levels are there in science olympiad?\n",
      "where are the singers of florida georgia line from?\n",
      "who sings lead on wouldnt it be nice?\n",
      "who is the main character in shadow of mordor?\n",
      "where are the next olympics to be held?\n",
      "when did game of thrones season 7 start?\n",
      "when does hook show up in once upon a time?\n",
      "when was the last time georgia tech won a national championship?\n",
      "who plays victor in days of our lives?\n",
      "who won the last triple crown in baseball?\n",
      "when does the football transfer window open in 2018?\n",
      "what episode of mr young do adam and echo kiss?\n",
      "when is game of thrones season 7 episode 7 releasing?\n",
      "who is the architect of sheikh zayed mosque?\n",
      "who is the director of iron man 3?\n",
      "who is one of the first german composers that we know about?\n",
      "where do they move to in cheaper by the dozen?\n",
      "who played bass on and justice for all?\n",
      "zen and the art of motorcycle maintenance bikes?\n",
      "when did texas become part of united states?\n",
      "the atlantoaxial joint is an example of what type of joint?\n",
      "what is the fastest roller coaster in california?\n",
      "when did they start to build the great wall of china?\n",
      "what type of reaction is the rusting of iron?\n",
      "where do the flyers play their home games?\n",
      "where does something old something new something borrowed something blue come from?\n"
     ]
    }
   ],
   "source": [
    "question_texts = [q.strip(\"?\") + \"?\" for q in test_data['question'].tolist()]\n",
    "print(\"\\n\".join(question_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Retrieve relevant context\n",
    "\n",
    "Fetch paragraphs similar to the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "relevant_contexts = []\n",
    "\n",
    "for question_text in question_texts:\n",
    "    relevant_chunks = chroma.query(\n",
    "        query_texts=[question_text],\n",
    "        n_results=5,\n",
    "    )\n",
    "    relevant_contexts.append(relevant_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Get the set of chunks for one of the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "Paragraph index :  268\n",
      "Paragraph :  Chris Carter (right-handed hitter)\n",
      "2.2 Oakland Athletics 2.3 Houston Astros 2.4 Milwaukee Brewers 2.5 New York Yankees 2.6 Return to the Oakland Athletics 3 Personal life 4 References 5 External links Early life and career ( edit ) Carter was born in Redwood City , California . At approximately age 7 or 8 , his family moved to Las Vegas . He attended Sierra Vista High School . In 2005 , Sierra Vista 's baseball team won the Nevada Interscholastic Activities Association Class 4A state championship . Professional career ( edit ) Draft and minors ( edit ) Carter was drafted by the Chicago White Sox in the 15th round of the 2005 Major League Baseball Draft . Carter began his professional career with the Bristol White Sox of the Rookie - level Appalachian League in 2005 . He hit 10 home runs and had 37 runs batted in ( RBIs ) . He played for two teams in the 2006 season . The teams included the Great Falls White Sox of the Rookie - level Pioneer League and the Kannapolis Intimidators of the Class A South Atlantic League . He had a combined total of 16 home runs and 63 RBIs . He played for Kannapolis in the 2007 season where he hit 25 home runs and had 93 RBIs . During the 2007 offseason , the White Sox traded Carter to the Arizona Diamondbacks for Carlos Quentin . Carter with the Athletics in 2012 Oakland Athletics ( edit ) Two weeks after\n",
      "Distance :  0.6766292452812195\n",
      "=========\n",
      "Paragraph index :  272\n",
      "Paragraph :  Chris Carter (right-handed hitter)\n",
      ", the New York Yankees signed Carter to a one - year contract , worth $3.5 million . Carter batted . 204 with eight home runs and 70 strikeouts before the Yankees designated him for assignment on June 24 . He was called back up by the Yankees on June 29 when his replacement at first base , Tyler Austin , landed on the disabled list . On July 4 , he was again designated for assignment , this time to make room for Ji - man Choi on the roster . He was released on July 10 . Return to the Oakland Athletics ( edit ) Carter signed a minor league contract with the Oakland Athletics on July 21 , 2017 , and was assigned to the Nashville Sounds of the PCL . Personal life ( edit ) Carter 's father , Vernon , played basketball for Rancho High School in North Las Vegas . Carter is a car enthusiast . He owns a Shelby Super Snake . References ( edit ) ^ Jump up to : `` Get to Know : Brewers first baseman Chris Carter '' . Retrieved February 17 , 2017 . ^ Jump up to : `` Powerful Carter always had a single focus '' . Retrieved February 17 , 2017 . Jump up ^ Merkin , Scott ( December 3 , 2007 ) . `` White Sox trade for outfielder Quentin '' . Chicago White Sox . Retrieved July 16 , 2008 . Jump\n",
      "Distance :  0.6858611106872559\n",
      "=========\n",
      "Paragraph index :  269\n",
      "Paragraph :  Chris Carter (right-handed hitter)\n",
      "he was traded to Arizona , the Diamondbacks traded Carter , Carlos González , Brett Anderson , Aaron Cunningham , Greg Smith , and Dana Eveland to the Oakland Athletics for Dan Haren and Connor Robertson . He played for the Stockton Ports of the Class A-Advanced California League in the 2008 season where he hit 39 home runs and had 104 RBIs . Carter was named the California League Rookie of the Year for the 2008 season . In 2009 , Carter split time between the Midland RockHounds of the Class AA Texas League and the Sacramento River Cats of the Class AAA Pacific Coast League ( PCL ) , putting a . 329 batting average ( a 70 - point increase from 2008 ) , 28 homers and 115 RBIs combined . In 2008 and 2009 , Baseball America ranked Carter as one of the top 10 prospects in the Athletics ' organization . Also in 2008 and 2009 , Carter was the Oakland Athletics ' Minor League Player of Year . Carter was placed on the A 's 40 - man roster on November 20 , 2009 . In 2009 , he was named the This Year in Minor League Baseball Awards `` Overall Hitter of The Year '' . On August 9 , 2010 , Carter was promoted to Oakland and went 0 -- for -- 3 in his first game . On August 16 , Carter was demoted to Sacramento after starting his career 0\n",
      "Distance :  0.7151550054550171\n",
      "=========\n",
      "Paragraph index :  271\n",
      "Paragraph :  Chris Carter (right-handed hitter)\n",
      "slower for Carter , as he batted only . 153 throughout the entire month of April . Carter would turn his fortunes around after the All - Star break though , as finished with a . 227 batting average and career highs of 37 home runs and 88 RBI . On January 14 , 2015 , Carter and the Astros agreed to a one - year contract worth $4.175 million , avoiding arbitration . Carter had a disappointing 2015 season for the Astros ; Carter was the team 's starting first baseman , but hit only . 199 in 129 games . However , he still managed to hit 24 home runs , and then hit . 294 with a home run against the Kansas City Royals during the 2015 American League Division Series . At the conclusion of the 2015 season Carter was non tendered by the Astros and he became a free agent . Milwaukee Brewers ( edit ) On January 6 , 2016 , Carter signed a one - year , $2.5 million contract with the Milwaukee Brewers . He posted a . 321 on - base percentage and hit 41 home runs , leading the National League in 2016 . However , he had a . 222 batting average and led the league with 206 strikeouts . The Brewers did not tender Carter a contract for the 2017 , making him a free agent . New York Yankees ( edit ) On February 16 , 2017\n",
      "Distance :  0.808864414691925\n",
      "=========\n",
      "Paragraph index :  275\n",
      "Paragraph :  Chris Carter (right-handed hitter)\n",
      "External links ( edit ) Wikimedia Commons has media related to Chris Carter ( baseball player born 1986 ) . Career statistics and player information from MLB , or Baseball - Reference , or Fangraphs , or The Baseball Cube , or Baseball - Reference ( Minors ) ( hide ) National League season home run leaders 1876 : Hall 1877 : Pike 1878 : Hines 1879 : C. Jones 1880 : Stovey & O'Rourke 1881 : Brouthers 1882 : Wood 1883 : Ewing 1884 : Williamson 1885 : Dalrymple 1886 : Brouthers & Richardson 1887 : O'Brien 1888 : Ryan 1889 : Thompson 1890 : Burns , Tiernan & Wilmot 1891 : Tiernan & Stovey 1892 : Holliday 1893 : Delahanty 1894 : Duffy 1895 : Thompson 1896 : Joyce & Delahanty 1897 : Duffy 1898 : J. Collins 1899 : Freeman 1900 : Long 1901 : Crawford 1902 : Leach 1903 : Sheckard 1904 : Lumley 1905 : Odwell 1906 : Jordan 1907 : Brain 1908 : Jordan 1909 : Murray 1910 : Schulte & Beck 1911 : Schulte 1912 : Zimmerman 1913 : Cravath 1914 : Cravath 1915 : Cravath 1916 : C. Williams & Robertson 1917 : Cravath & Robertson 1918 : Cravath 1919 : Cravath 1920 : C. Williams 1921 : Kelly 1922 : Hornsby 1923 : C. Williams 1924 : Fournier 1925 : Hornsby 1926 : Wilson 1927 : C. Williams & Wilson 1928 : Wilson & Bottomley 1929 : Klein 1930 : Wilson\n",
      "Distance :  0.8511186838150024\n"
     ]
    }
   ],
   "source": [
    "sample_chunks = relevant_contexts[0]\n",
    "for i, chunk in enumerate(sample_chunks['documents'][0]):\n",
    "    print(\"=========\")\n",
    "    print(\"Paragraph index : \", sample_chunks['ids'][0][i])\n",
    "    print(\"Paragraph : \", chunk)\n",
    "    print(\"Distance : \", sample_chunks['distances'][0][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Feed the context and the questions to `watsonx.ai` model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define instructions for the model.\n",
    "\n",
    "**Note:** Please **start with using [watsonx.ai Prompt Lab](https://dataplatform.cloud.ibm.com/wx/home?context=wx)** to find better prompts that provides you the best result on a small subset training records (under `train_data` variable). Make sure to not run an inference of all of `train_data`, as it'll take a long time to get the results. To get a sample from `train_data`, you can use e.g.`train_data.head(n=10)` to get first 10 records, or `train_data.sample(n=10)` to get random 10 records. Only once you have identified the best performing prompt, update this notebook to use the prompt and compute the metrics on the test data.\n",
    "\n",
    "**Action:** Please edit the below cell and add your own prompt here. In the below prompt, we have the instruction (first sentence) and one example included in the prompt.  If you want to change the prompt or add your own examples or more examples, please change the below prompt accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def make_prompt(context, question_text):\n",
    "    return (f\"Please answer the following.\\n\"\n",
    "          + f\"{context}:\\n\\n\"\n",
    "          + f\"{question_text}\")\n",
    "\n",
    "prompt_texts = []\n",
    "\n",
    "for relevant_context, question_text in zip(relevant_contexts, question_texts):\n",
    "    context = \"\\n\\n\\n\".join(relevant_context[\"documents\"][0])\n",
    "    prompt_text = make_prompt(context, question_text)\n",
    "    prompt_texts.append(prompt_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Inspect prompt for sample question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please answer the following.\n",
      "Chris Carter (right-handed hitter)\n",
      "2.2 Oakland Athletics 2.3 Houston Astros 2.4 Milwaukee Brewers 2.5 New York Yankees 2.6 Return to the Oakland Athletics 3 Personal life 4 References 5 External links Early life and career ( edit ) Carter was born in Redwood City , California . At approximately age 7 or 8 , his family moved to Las Vegas . He attended Sierra Vista High School . In 2005 , Sierra Vista 's baseball team won the Nevada Interscholastic Activities Association Class 4A state championship . Professional career ( edit ) Draft and minors ( edit ) Carter was drafted by the Chicago White Sox in the 15th round of the 2005 Major League Baseball Draft . Carter began his professional career with the Bristol White Sox of the Rookie - level Appalachian League in 2005 . He hit 10 home runs and had 37 runs batted in ( RBIs ) . He played for two teams in the 2006 season . The teams included the Great Falls White Sox of the Rookie - level Pioneer League and the Kannapolis Intimidators of the Class A South Atlantic League . He had a combined total of 16 home runs and 63 RBIs . He played for Kannapolis in the 2007 season where he hit 25 home runs and had 93 RBIs . During the 2007 offseason , the White Sox traded Carter to the Arizona Diamondbacks for Carlos Quentin . Carter with the Athletics in 2012 Oakland Athletics ( edit ) Two weeks after\n",
      "\n",
      "\n",
      "Chris Carter (right-handed hitter)\n",
      ", the New York Yankees signed Carter to a one - year contract , worth $3.5 million . Carter batted . 204 with eight home runs and 70 strikeouts before the Yankees designated him for assignment on June 24 . He was called back up by the Yankees on June 29 when his replacement at first base , Tyler Austin , landed on the disabled list . On July 4 , he was again designated for assignment , this time to make room for Ji - man Choi on the roster . He was released on July 10 . Return to the Oakland Athletics ( edit ) Carter signed a minor league contract with the Oakland Athletics on July 21 , 2017 , and was assigned to the Nashville Sounds of the PCL . Personal life ( edit ) Carter 's father , Vernon , played basketball for Rancho High School in North Las Vegas . Carter is a car enthusiast . He owns a Shelby Super Snake . References ( edit ) ^ Jump up to : `` Get to Know : Brewers first baseman Chris Carter '' . Retrieved February 17 , 2017 . ^ Jump up to : `` Powerful Carter always had a single focus '' . Retrieved February 17 , 2017 . Jump up ^ Merkin , Scott ( December 3 , 2007 ) . `` White Sox trade for outfielder Quentin '' . Chicago White Sox . Retrieved July 16 , 2008 . Jump\n",
      "\n",
      "\n",
      "Chris Carter (right-handed hitter)\n",
      "he was traded to Arizona , the Diamondbacks traded Carter , Carlos González , Brett Anderson , Aaron Cunningham , Greg Smith , and Dana Eveland to the Oakland Athletics for Dan Haren and Connor Robertson . He played for the Stockton Ports of the Class A-Advanced California League in the 2008 season where he hit 39 home runs and had 104 RBIs . Carter was named the California League Rookie of the Year for the 2008 season . In 2009 , Carter split time between the Midland RockHounds of the Class AA Texas League and the Sacramento River Cats of the Class AAA Pacific Coast League ( PCL ) , putting a . 329 batting average ( a 70 - point increase from 2008 ) , 28 homers and 115 RBIs combined . In 2008 and 2009 , Baseball America ranked Carter as one of the top 10 prospects in the Athletics ' organization . Also in 2008 and 2009 , Carter was the Oakland Athletics ' Minor League Player of Year . Carter was placed on the A 's 40 - man roster on November 20 , 2009 . In 2009 , he was named the This Year in Minor League Baseball Awards `` Overall Hitter of The Year '' . On August 9 , 2010 , Carter was promoted to Oakland and went 0 -- for -- 3 in his first game . On August 16 , Carter was demoted to Sacramento after starting his career 0\n",
      "\n",
      "\n",
      "Chris Carter (right-handed hitter)\n",
      "slower for Carter , as he batted only . 153 throughout the entire month of April . Carter would turn his fortunes around after the All - Star break though , as finished with a . 227 batting average and career highs of 37 home runs and 88 RBI . On January 14 , 2015 , Carter and the Astros agreed to a one - year contract worth $4.175 million , avoiding arbitration . Carter had a disappointing 2015 season for the Astros ; Carter was the team 's starting first baseman , but hit only . 199 in 129 games . However , he still managed to hit 24 home runs , and then hit . 294 with a home run against the Kansas City Royals during the 2015 American League Division Series . At the conclusion of the 2015 season Carter was non tendered by the Astros and he became a free agent . Milwaukee Brewers ( edit ) On January 6 , 2016 , Carter signed a one - year , $2.5 million contract with the Milwaukee Brewers . He posted a . 321 on - base percentage and hit 41 home runs , leading the National League in 2016 . However , he had a . 222 batting average and led the league with 206 strikeouts . The Brewers did not tender Carter a contract for the 2017 , making him a free agent . New York Yankees ( edit ) On February 16 , 2017\n",
      "\n",
      "\n",
      "Chris Carter (right-handed hitter)\n",
      "External links ( edit ) Wikimedia Commons has media related to Chris Carter ( baseball player born 1986 ) . Career statistics and player information from MLB , or Baseball - Reference , or Fangraphs , or The Baseball Cube , or Baseball - Reference ( Minors ) ( hide ) National League season home run leaders 1876 : Hall 1877 : Pike 1878 : Hines 1879 : C. Jones 1880 : Stovey & O'Rourke 1881 : Brouthers 1882 : Wood 1883 : Ewing 1884 : Williamson 1885 : Dalrymple 1886 : Brouthers & Richardson 1887 : O'Brien 1888 : Ryan 1889 : Thompson 1890 : Burns , Tiernan & Wilmot 1891 : Tiernan & Stovey 1892 : Holliday 1893 : Delahanty 1894 : Duffy 1895 : Thompson 1896 : Joyce & Delahanty 1897 : Duffy 1898 : J. Collins 1899 : Freeman 1900 : Long 1901 : Crawford 1902 : Leach 1903 : Sheckard 1904 : Lumley 1905 : Odwell 1906 : Jordan 1907 : Brain 1908 : Jordan 1909 : Murray 1910 : Schulte & Beck 1911 : Schulte 1912 : Zimmerman 1913 : Cravath 1914 : Cravath 1915 : Cravath 1916 : C. Williams & Robertson 1917 : Cravath & Robertson 1918 : Cravath 1919 : Cravath 1920 : C. Williams 1921 : Kelly 1922 : Hornsby 1923 : C. Williams 1924 : Fournier 1925 : Hornsby 1926 : Wilson 1927 : C. Williams & Wilson 1928 : Wilson & Bottomley 1929 : Klein 1930 : Wilson:\n",
      "\n",
      "who did chris carter play for last year?\n"
     ]
    }
   ],
   "source": [
    "print(prompt_texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Defining the model parameters\n",
    "We need to provide a set of model parameters that will influence the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n",
    "\n",
    "parameters = {\n",
    "    GenParams.MAX_NEW_TOKENS: \"greedy\",\n",
    "    GenParams.MAX_NEW_TOKENS: 1,\n",
    "    GenParams.MAX_NEW_TOKENS: 50\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Initialize the `Model` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning.foundation_models import Model\n",
    "\n",
    "model = Model(\n",
    "    model_id=model_id,\n",
    "    params=parameters,\n",
    "    credentials=credentials,\n",
    "    project_id=project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Generate a retrieval-augmented response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Execution of this cell could take several minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for prompt_text in prompt_texts:\n",
    "    results.append(model.generate_text(prompt=prompt_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question =  who did chris carter play for last year\n",
      "Answer =  Milwaukee Brewers\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Milwaukee Brewers\n",
      "\n",
      "\n",
      "Question =  what is the latest version of safari on mac\n",
      "Answer =  10.1. 2\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Safari 11\n",
      "\n",
      "\n",
      "Question =  when did bucharest become the capital of romania\n",
      "Answer =  1862\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  1862\n",
      "\n",
      "\n",
      "Question =  who did jeffrey dean morgan play on supernatural\n",
      "Answer =  John Winchester\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  John Eric Winchester\n",
      "\n",
      "\n",
      "Question =  who is the shortest man that ever lived\n",
      "Answer =  Chandra Bahadur Dangi\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Chandra Bahadur Dangi\n",
      "\n",
      "\n",
      "Question =  how many seconds do you have to throw a grenade\n",
      "Answer =  4\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  4 and 5 seconds\n",
      "\n",
      "\n",
      "Question =  who is known as a father of indian cricket\n",
      "Answer =  Buchi Babu Naidu\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  M. Suryanarayan\n",
      "\n",
      "\n",
      "Question =  what is the name of the period in japanese history that began in 1868\n",
      "Answer =  Meiji\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Meiji\n",
      "\n",
      "\n",
      "Question =  harold and kumar go to white castle where was it filmed\n",
      "Answer =  Toronto\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Toronto , Ontario , Canada\n",
      "\n",
      "\n",
      "Question =  how many games have the capitals won in the playoffs\n",
      "Answer =  446\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  two\n",
      "\n",
      "\n",
      "Question =  what is the best selling nintendo game of all time\n",
      "Answer =  Super Mario Bros\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Wii Sports\n",
      "\n",
      "\n",
      "Question =  korean movie about a man on an island\n",
      "Answer =  Jump up                        \n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Castaway on the Moon\n",
      "\n",
      "\n",
      "Question =  who plays lorelai in hannah montana the movie\n",
      "Answer =  Melora Hardin\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Melora Hardin\n",
      "\n",
      "\n",
      "Question =  what season of greys anatomy was the plane crash\n",
      "Answer =  seventh\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  the eighth season\n",
      "\n",
      "\n",
      "Question =  who made call of duty black ops 2\n",
      "Answer =  Treyarch\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Treyarch\n",
      "\n",
      "\n",
      "Question =  when was the last solar eclipse seen in north america\n",
      "Answer =  August 21, 2017\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  August 21 , 2017\n",
      "\n",
      "\n",
      "Question =  who is hosting the fifa world cup in 2022\n",
      "Answer =  Qatar\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Qatar\n",
      "\n",
      "\n",
      "Question =  what is the record for wins in major league baseball\n",
      "Answer =  116\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  116\n",
      "\n",
      "\n",
      "Question =  big boss 2 telugu set location in hyderabad\n",
      "Answer =  Bigg Boss Telugu\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Annapurna Studios , Hyderabad\n",
      "\n",
      "\n",
      "Question =  who did the us support in the korean war\n",
      "Answer =  South Korea\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  South Korea\n",
      "\n",
      "\n",
      "Question =  what is the caterpillar smoking in alice in wonderland\n",
      "Answer =  hookah\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  a hookah\n",
      "\n",
      "\n",
      "Question =  how much aid does us give to other countries\n",
      "Answer =  less than 1 percent of the US federal budget goes towards foreign aid\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  $43.10 billion\n",
      "\n",
      "\n",
      "Question =  who plays jake on two and a half\n",
      "Answer =  Charlie Weber\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Angus Turner Jones\n",
      "\n",
      "\n",
      "Question =  what do you call a bundle of hay\n",
      "Answer =  haystack\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  bales\n",
      "\n",
      "\n",
      "Question =  how many levels are there in science olympiad\n",
      "Answer =  three\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  two\n",
      "\n",
      "\n",
      "Question =  where are the singers of florida georgia line from\n",
      "Answer =  Florida Georgia Line\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Monroe , Georgia::Ormond Beach , Florida\n",
      "\n",
      "\n",
      "Question =  who sings lead on wouldnt it be nice\n",
      "Answer =  Brian Wilson\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Brian Wilson::Mike Love\n",
      "\n",
      "\n",
      "Question =  who is the main character in shadow of mordor\n",
      "Answer =  Talion\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Talion\n",
      "\n",
      "\n",
      "Question =  where are the next olympics to be held\n",
      "Answer =  Pyeongchang\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Tokyo::Beijing\n",
      "\n",
      "\n",
      "Question =  when did game of thrones season 7 start\n",
      "Answer =  July 16\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  July 16 , 2017\n",
      "\n",
      "\n",
      "Question =  when does hook show up in once upon a time\n",
      "Answer =  season 2\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  The Crocodile\n",
      "\n",
      "\n",
      "Question =  when was the last time georgia tech won a national championship\n",
      "Answer =  \n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  1990\n",
      "\n",
      "\n",
      "Question =  who plays victor in days of our lives\n",
      "Answer =  john aniston\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  John Anthony Aniston\n",
      "\n",
      "\n",
      "Question =  who won the last triple crown in baseball\n",
      "Answer =  Miguel Cabrera\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Miguel Cabrera\n",
      "\n",
      "\n",
      "Question =  when does the football transfer window open in 2018\n",
      "Answer =  on August 9\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  August 9\n",
      "\n",
      "\n",
      "Question =  what episode of mr young do adam and echo kiss\n",
      "Answer =  Mr. Meteor\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  `` Mr. First Impression ''\n",
      "\n",
      "\n",
      "Question =  when is game of thrones season 7 episode 7 releasing\n",
      "Answer =  Game of Thrones (season 7)\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  July 16 , 2017\n",
      "\n",
      "\n",
      "Question =  who is the architect of sheikh zayed mosque\n",
      "Answer =  Yousef Abdelky\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Yousef Abdelky\n",
      "\n",
      "\n",
      "Question =  who is the director of iron man 3\n",
      "Answer =  Shane Black\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Shane Black\n",
      "\n",
      "\n",
      "Question =  who is one of the first german composers that we know about\n",
      "Answer =  Johann Jakob Froberger\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Adam von Fulda\n",
      "\n",
      "\n",
      "Question =  where do they move to in cheaper by the dozen\n",
      "Answer =  Evanston\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Evanston , IL\n",
      "\n",
      "\n",
      "Question =  who played bass on and justice for all\n",
      "Answer =  Jason Newsted\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Jason Newsted\n",
      "\n",
      "\n",
      "Question =  zen and the art of motorcycle maintenance bikes\n",
      "Answer =  Honda CB77\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  CB77 Super Hawk\n",
      "\n",
      "\n",
      "Question =  when did texas become part of united states\n",
      "Answer =  December 29 , 1845\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  1845\n",
      "\n",
      "\n",
      "Question =  the atlantoaxial joint is an example of what type of joint\n",
      "Answer =  pivot\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  a pivot joint\n",
      "\n",
      "\n",
      "Question =  what is the fastest roller coaster in california\n",
      "Answer =  Goliath\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Formula Rossa\n",
      "\n",
      "\n",
      "Question =  when did they start to build the great wall of china\n",
      "Answer =  771 -- 476 BC\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  771 -- 476 BC\n",
      "\n",
      "\n",
      "Question =  what type of reaction is the rusting of iron\n",
      "Answer =  electrochemical\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  electrochemical\n",
      "\n",
      "\n",
      "Question =  where do the flyers play their home games\n",
      "Answer =  Wells Fargo Center\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Wells Fargo Center\n",
      "\n",
      "\n",
      "Question =  where does something old something new something borrowed something blue come from\n",
      "Answer =  Lancashire\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Lancashire\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, result in enumerate(results):\n",
    "    print(\"Question = \", test_data.iloc[idx]['question'])\n",
    "    print(\"Answer = \", result)\n",
    "    print(\"Expected Answer(s) (may not be appear with exact wording in the dataset) = \", test_data.iloc[idx]['answers'])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"score\"></a>\n",
    "## Calculate rougeL metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this sample notebook `rouge_score` module was used for rougeL calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Rouge Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Note:** The Rouge (Recall-Oriented Understudy for Gisting Evaluation) metric is a set of evaluation measures used in natural language processing (NLP) and specifically in text summarization and machine translation tasks. The Rouge metrics are designed to assess the quality of generated summaries or translations by comparing them to one or more reference texts.\n",
    "\n",
    "The main idea behind Rouge is to measure the overlap between the generated summary (or translation) and the reference text(s) in terms of n-grams or longest common subsequences. By calculating recall, precision, and F1 scores based on these overlapping units, Rouge provides a quantitative assessment of the summary's content overlap with the reference(s).\n",
    "\n",
    "Rouge-1 focuses on individual word overlap, Rouge-2 considers pairs of consecutive words, and Rouge-L takes into account the ordering of words and phrases. These metrics provide different perspectives on the similarity between two texts and can be used to evaluate different aspects of summarization or text generation models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "def get_rouge_score(predictions, references):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL', 'rougeLsum'])\n",
    "    aggregate_score = defaultdict(list)\n",
    "\n",
    "    for result, ref in zip(predictions, references):\n",
    "        for key, val in scorer.score(result, ref).items():\n",
    "            aggregate_score[key].append(val.fmeasure)\n",
    "\n",
    "    scores = {}\n",
    "    for key in aggregate_score:\n",
    "        scores[key] = np.mean(aggregate_score[key])\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.5479999999999999, 'rouge2': 0.25666666666666665, 'rougeL': 0.5429999999999999, 'rougeLsum': 0.5429999999999999}\n"
     ]
    }
   ],
   "source": [
    "print(get_rouge_score(results, test_data.answers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Copyright © 2023 IBM. This notebook and its source code are released under the terms of the MIT License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
